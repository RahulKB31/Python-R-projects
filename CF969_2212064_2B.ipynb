{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2B: Optimisation and Machine Learning in Finance – Software - Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    In all the models used below we tried to classify the data into 16 categories and predicted whether the firm is a investment grade or not along with its accuracy in prediction. The datset consists of 1700 observations of 26 financial and accounting metrics for a set of firms in several different industries. Here we will first implement linear regression model to predict the ratings. The steps followed here are importing of libraries and loading of data sets. We then preprocess the data and then split the data into training and testing sets. We then train the model on the training data sets and test it on testing datasets to evaluate its performance. Use the trained model for new predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge,Lasso, LinearRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sales/Revenues</th>\n",
       "      <th>Gross Margin</th>\n",
       "      <th>EBITDA</th>\n",
       "      <th>EBITDA Margin</th>\n",
       "      <th>Net Income Before Extras</th>\n",
       "      <th>Total Debt</th>\n",
       "      <th>Net Debt</th>\n",
       "      <th>LT Debt</th>\n",
       "      <th>ST Debt</th>\n",
       "      <th>Cash</th>\n",
       "      <th>...</th>\n",
       "      <th>Interest Coverage</th>\n",
       "      <th>Total Liquidity</th>\n",
       "      <th>Current Liquidity</th>\n",
       "      <th>Current Liabilities</th>\n",
       "      <th>EPS Before Extras</th>\n",
       "      <th>PE</th>\n",
       "      <th>ROA</th>\n",
       "      <th>ROE</th>\n",
       "      <th>InvGrd</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.005496</td>\n",
       "      <td>0.030763</td>\n",
       "      <td>0.018885</td>\n",
       "      <td>0.024515</td>\n",
       "      <td>0.146849</td>\n",
       "      <td>-0.029710</td>\n",
       "      <td>-0.019296</td>\n",
       "      <td>-0.042648</td>\n",
       "      <td>0.049875</td>\n",
       "      <td>-0.133716</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136748</td>\n",
       "      <td>0.392143</td>\n",
       "      <td>-0.184887</td>\n",
       "      <td>0.062781</td>\n",
       "      <td>0.148305</td>\n",
       "      <td>0.100409</td>\n",
       "      <td>0.163266</td>\n",
       "      <td>0.102521</td>\n",
       "      <td>1</td>\n",
       "      <td>A1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.005496</td>\n",
       "      <td>0.030763</td>\n",
       "      <td>0.088716</td>\n",
       "      <td>0.094733</td>\n",
       "      <td>0.146849</td>\n",
       "      <td>-0.029710</td>\n",
       "      <td>-0.019296</td>\n",
       "      <td>-0.042648</td>\n",
       "      <td>0.049875</td>\n",
       "      <td>-0.133716</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214657</td>\n",
       "      <td>0.392143</td>\n",
       "      <td>-0.184887</td>\n",
       "      <td>0.062781</td>\n",
       "      <td>0.148305</td>\n",
       "      <td>-0.089598</td>\n",
       "      <td>0.163266</td>\n",
       "      <td>0.102521</td>\n",
       "      <td>1</td>\n",
       "      <td>A1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.007045</td>\n",
       "      <td>0.023159</td>\n",
       "      <td>0.088716</td>\n",
       "      <td>0.096440</td>\n",
       "      <td>0.108590</td>\n",
       "      <td>0.039410</td>\n",
       "      <td>0.034268</td>\n",
       "      <td>0.009059</td>\n",
       "      <td>0.250371</td>\n",
       "      <td>0.101315</td>\n",
       "      <td>...</td>\n",
       "      <td>0.205290</td>\n",
       "      <td>0.483257</td>\n",
       "      <td>-0.017877</td>\n",
       "      <td>0.121357</td>\n",
       "      <td>0.110656</td>\n",
       "      <td>-0.045142</td>\n",
       "      <td>0.105711</td>\n",
       "      <td>0.103378</td>\n",
       "      <td>1</td>\n",
       "      <td>A1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.009396</td>\n",
       "      <td>0.028400</td>\n",
       "      <td>0.088716</td>\n",
       "      <td>0.099046</td>\n",
       "      <td>0.146137</td>\n",
       "      <td>0.030071</td>\n",
       "      <td>0.036938</td>\n",
       "      <td>-0.016964</td>\n",
       "      <td>0.356994</td>\n",
       "      <td>-0.052606</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232991</td>\n",
       "      <td>0.996955</td>\n",
       "      <td>-0.122017</td>\n",
       "      <td>0.079051</td>\n",
       "      <td>0.151639</td>\n",
       "      <td>-0.008231</td>\n",
       "      <td>0.162421</td>\n",
       "      <td>0.132295</td>\n",
       "      <td>1</td>\n",
       "      <td>A1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.009009</td>\n",
       "      <td>0.027714</td>\n",
       "      <td>0.088716</td>\n",
       "      <td>0.098611</td>\n",
       "      <td>0.123500</td>\n",
       "      <td>0.024224</td>\n",
       "      <td>0.034445</td>\n",
       "      <td>-0.034132</td>\n",
       "      <td>0.461894</td>\n",
       "      <td>-0.090869</td>\n",
       "      <td>...</td>\n",
       "      <td>0.172906</td>\n",
       "      <td>1.711426</td>\n",
       "      <td>-0.161561</td>\n",
       "      <td>0.084319</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.015528</td>\n",
       "      <td>0.156427</td>\n",
       "      <td>0.225144</td>\n",
       "      <td>1</td>\n",
       "      <td>A1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sales/Revenues  Gross Margin    EBITDA  EBITDA Margin  \\\n",
       "0       -0.005496      0.030763  0.018885       0.024515   \n",
       "1       -0.005496      0.030763  0.088716       0.094733   \n",
       "2       -0.007045      0.023159  0.088716       0.096440   \n",
       "3       -0.009396      0.028400  0.088716       0.099046   \n",
       "4       -0.009009      0.027714  0.088716       0.098611   \n",
       "\n",
       "   Net Income Before Extras  Total Debt  Net Debt   LT Debt   ST Debt  \\\n",
       "0                  0.146849   -0.029710 -0.019296 -0.042648  0.049875   \n",
       "1                  0.146849   -0.029710 -0.019296 -0.042648  0.049875   \n",
       "2                  0.108590    0.039410  0.034268  0.009059  0.250371   \n",
       "3                  0.146137    0.030071  0.036938 -0.016964  0.356994   \n",
       "4                  0.123500    0.024224  0.034445 -0.034132  0.461894   \n",
       "\n",
       "       Cash  ...  Interest Coverage  Total Liquidity  Current Liquidity  \\\n",
       "0 -0.133716  ...           0.136748         0.392143          -0.184887   \n",
       "1 -0.133716  ...           0.214657         0.392143          -0.184887   \n",
       "2  0.101315  ...           0.205290         0.483257          -0.017877   \n",
       "3 -0.052606  ...           0.232991         0.996955          -0.122017   \n",
       "4 -0.090869  ...           0.172906         1.711426          -0.161561   \n",
       "\n",
       "   Current Liabilities  EPS Before Extras        PE       ROA       ROE  \\\n",
       "0             0.062781           0.148305  0.100409  0.163266  0.102521   \n",
       "1             0.062781           0.148305 -0.089598  0.163266  0.102521   \n",
       "2             0.121357           0.110656 -0.045142  0.105711  0.103378   \n",
       "3             0.079051           0.151639 -0.008231  0.162421  0.132295   \n",
       "4             0.084319           0.130435  0.015528  0.156427  0.225144   \n",
       "\n",
       "   InvGrd  Rating  \n",
       "0       1      A1  \n",
       "1       1      A1  \n",
       "2       1      A1  \n",
       "3       1      A1  \n",
       "4       1      A1  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading of datasets\n",
    "df = pd.read_csv('MLF_GP1_CreditScore.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sales/Revenues</th>\n",
       "      <th>Gross Margin</th>\n",
       "      <th>EBITDA</th>\n",
       "      <th>EBITDA Margin</th>\n",
       "      <th>Net Income Before Extras</th>\n",
       "      <th>Total Debt</th>\n",
       "      <th>Net Debt</th>\n",
       "      <th>LT Debt</th>\n",
       "      <th>ST Debt</th>\n",
       "      <th>Cash</th>\n",
       "      <th>...</th>\n",
       "      <th>CFO</th>\n",
       "      <th>Interest Coverage</th>\n",
       "      <th>Total Liquidity</th>\n",
       "      <th>Current Liquidity</th>\n",
       "      <th>Current Liabilities</th>\n",
       "      <th>EPS Before Extras</th>\n",
       "      <th>PE</th>\n",
       "      <th>ROA</th>\n",
       "      <th>ROE</th>\n",
       "      <th>InvGrd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1700.000000</td>\n",
       "      <td>1700.000000</td>\n",
       "      <td>1700.000000</td>\n",
       "      <td>1700.000000</td>\n",
       "      <td>1700.000000</td>\n",
       "      <td>1700.000000</td>\n",
       "      <td>1700.000000</td>\n",
       "      <td>1700.000000</td>\n",
       "      <td>1700.000000</td>\n",
       "      <td>1700.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1700.000000</td>\n",
       "      <td>1700.000000</td>\n",
       "      <td>1700.000000</td>\n",
       "      <td>1700.000000</td>\n",
       "      <td>1700.000000</td>\n",
       "      <td>1700.000000</td>\n",
       "      <td>1700.000000</td>\n",
       "      <td>1700.000000</td>\n",
       "      <td>1700.000000</td>\n",
       "      <td>1700.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.050378</td>\n",
       "      <td>0.026007</td>\n",
       "      <td>0.068718</td>\n",
       "      <td>0.021074</td>\n",
       "      <td>0.123026</td>\n",
       "      <td>0.822405</td>\n",
       "      <td>-0.419810</td>\n",
       "      <td>1.255168</td>\n",
       "      <td>3.142797</td>\n",
       "      <td>0.466620</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.189317</td>\n",
       "      <td>0.298785</td>\n",
       "      <td>-0.855714</td>\n",
       "      <td>0.436002</td>\n",
       "      <td>0.072802</td>\n",
       "      <td>0.032196</td>\n",
       "      <td>0.497705</td>\n",
       "      <td>0.019394</td>\n",
       "      <td>-0.217604</td>\n",
       "      <td>0.757059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.161910</td>\n",
       "      <td>0.273768</td>\n",
       "      <td>0.237365</td>\n",
       "      <td>0.189025</td>\n",
       "      <td>14.475689</td>\n",
       "      <td>13.317075</td>\n",
       "      <td>28.385702</td>\n",
       "      <td>16.224453</td>\n",
       "      <td>51.986550</td>\n",
       "      <td>1.859494</td>\n",
       "      <td>...</td>\n",
       "      <td>5.668669</td>\n",
       "      <td>5.265291</td>\n",
       "      <td>22.926862</td>\n",
       "      <td>1.904282</td>\n",
       "      <td>0.266471</td>\n",
       "      <td>6.151994</td>\n",
       "      <td>12.102502</td>\n",
       "      <td>14.594193</td>\n",
       "      <td>15.389000</td>\n",
       "      <td>0.428986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.661715</td>\n",
       "      <td>-0.794722</td>\n",
       "      <td>-0.782254</td>\n",
       "      <td>-0.805153</td>\n",
       "      <td>-289.000000</td>\n",
       "      <td>-0.903014</td>\n",
       "      <td>-493.305578</td>\n",
       "      <td>-0.921515</td>\n",
       "      <td>-0.997692</td>\n",
       "      <td>-0.990982</td>\n",
       "      <td>...</td>\n",
       "      <td>-161.609425</td>\n",
       "      <td>-0.991976</td>\n",
       "      <td>-502.000000</td>\n",
       "      <td>-0.994141</td>\n",
       "      <td>-0.684678</td>\n",
       "      <td>-96.250000</td>\n",
       "      <td>-59.795133</td>\n",
       "      <td>-305.462167</td>\n",
       "      <td>-373.837267</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.005693</td>\n",
       "      <td>-0.020028</td>\n",
       "      <td>-0.022640</td>\n",
       "      <td>-0.042771</td>\n",
       "      <td>-0.158478</td>\n",
       "      <td>-0.076316</td>\n",
       "      <td>-0.120725</td>\n",
       "      <td>-0.094767</td>\n",
       "      <td>-0.337959</td>\n",
       "      <td>-0.195117</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.115159</td>\n",
       "      <td>-0.096996</td>\n",
       "      <td>-0.857013</td>\n",
       "      <td>-0.227327</td>\n",
       "      <td>-0.072734</td>\n",
       "      <td>-0.152894</td>\n",
       "      <td>-0.293521</td>\n",
       "      <td>-0.208483</td>\n",
       "      <td>-0.233955</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.034000</td>\n",
       "      <td>0.003403</td>\n",
       "      <td>0.049482</td>\n",
       "      <td>0.011134</td>\n",
       "      <td>0.056627</td>\n",
       "      <td>0.005886</td>\n",
       "      <td>-0.003060</td>\n",
       "      <td>-0.002078</td>\n",
       "      <td>0.043092</td>\n",
       "      <td>0.075820</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046983</td>\n",
       "      <td>0.043216</td>\n",
       "      <td>-0.229098</td>\n",
       "      <td>0.040446</td>\n",
       "      <td>0.041785</td>\n",
       "      <td>0.066027</td>\n",
       "      <td>-0.040405</td>\n",
       "      <td>-0.009403</td>\n",
       "      <td>-0.020392</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.083004</td>\n",
       "      <td>0.025595</td>\n",
       "      <td>0.124533</td>\n",
       "      <td>0.060566</td>\n",
       "      <td>0.222219</td>\n",
       "      <td>0.136449</td>\n",
       "      <td>0.160251</td>\n",
       "      <td>0.174735</td>\n",
       "      <td>0.649475</td>\n",
       "      <td>0.483113</td>\n",
       "      <td>...</td>\n",
       "      <td>0.216432</td>\n",
       "      <td>0.177340</td>\n",
       "      <td>0.512778</td>\n",
       "      <td>0.416067</td>\n",
       "      <td>0.161215</td>\n",
       "      <td>0.236046</td>\n",
       "      <td>0.168897</td>\n",
       "      <td>0.156136</td>\n",
       "      <td>0.201596</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.277229</td>\n",
       "      <td>3.202713</td>\n",
       "      <td>3.542425</td>\n",
       "      <td>4.141182</td>\n",
       "      <td>478.280075</td>\n",
       "      <td>281.604237</td>\n",
       "      <td>865.194595</td>\n",
       "      <td>289.388178</td>\n",
       "      <td>2038.000000</td>\n",
       "      <td>36.980037</td>\n",
       "      <td>...</td>\n",
       "      <td>13.005788</td>\n",
       "      <td>182.131887</td>\n",
       "      <td>280.138728</td>\n",
       "      <td>34.372455</td>\n",
       "      <td>4.194381</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>381.243282</td>\n",
       "      <td>474.847172</td>\n",
       "      <td>343.145356</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Sales/Revenues  Gross Margin       EBITDA  EBITDA Margin  \\\n",
       "count     1700.000000   1700.000000  1700.000000    1700.000000   \n",
       "mean         0.050378      0.026007     0.068718       0.021074   \n",
       "std          0.161910      0.273768     0.237365       0.189025   \n",
       "min         -0.661715     -0.794722    -0.782254      -0.805153   \n",
       "25%         -0.005693     -0.020028    -0.022640      -0.042771   \n",
       "50%          0.034000      0.003403     0.049482       0.011134   \n",
       "75%          0.083004      0.025595     0.124533       0.060566   \n",
       "max          2.277229      3.202713     3.542425       4.141182   \n",
       "\n",
       "       Net Income Before Extras   Total Debt     Net Debt      LT Debt  \\\n",
       "count               1700.000000  1700.000000  1700.000000  1700.000000   \n",
       "mean                   0.123026     0.822405    -0.419810     1.255168   \n",
       "std                   14.475689    13.317075    28.385702    16.224453   \n",
       "min                 -289.000000    -0.903014  -493.305578    -0.921515   \n",
       "25%                   -0.158478    -0.076316    -0.120725    -0.094767   \n",
       "50%                    0.056627     0.005886    -0.003060    -0.002078   \n",
       "75%                    0.222219     0.136449     0.160251     0.174735   \n",
       "max                  478.280075   281.604237   865.194595   289.388178   \n",
       "\n",
       "           ST Debt         Cash  ...          CFO  Interest Coverage  \\\n",
       "count  1700.000000  1700.000000  ...  1700.000000        1700.000000   \n",
       "mean      3.142797     0.466620  ...    -0.189317           0.298785   \n",
       "std      51.986550     1.859494  ...     5.668669           5.265291   \n",
       "min      -0.997692    -0.990982  ...  -161.609425          -0.991976   \n",
       "25%      -0.337959    -0.195117  ...    -0.115159          -0.096996   \n",
       "50%       0.043092     0.075820  ...     0.046983           0.043216   \n",
       "75%       0.649475     0.483113  ...     0.216432           0.177340   \n",
       "max    2038.000000    36.980037  ...    13.005788         182.131887   \n",
       "\n",
       "       Total Liquidity  Current Liquidity  Current Liabilities  \\\n",
       "count      1700.000000        1700.000000          1700.000000   \n",
       "mean         -0.855714           0.436002             0.072802   \n",
       "std          22.926862           1.904282             0.266471   \n",
       "min        -502.000000          -0.994141            -0.684678   \n",
       "25%          -0.857013          -0.227327            -0.072734   \n",
       "50%          -0.229098           0.040446             0.041785   \n",
       "75%           0.512778           0.416067             0.161215   \n",
       "max         280.138728          34.372455             4.194381   \n",
       "\n",
       "       EPS Before Extras           PE          ROA          ROE       InvGrd  \n",
       "count        1700.000000  1700.000000  1700.000000  1700.000000  1700.000000  \n",
       "mean            0.032196     0.497705     0.019394    -0.217604     0.757059  \n",
       "std             6.151994    12.102502    14.594193    15.389000     0.428986  \n",
       "min           -96.250000   -59.795133  -305.462167  -373.837267     0.000000  \n",
       "25%            -0.152894    -0.293521    -0.208483    -0.233955     1.000000  \n",
       "50%             0.066027    -0.040405    -0.009403    -0.020392     1.000000  \n",
       "75%             0.236046     0.168897     0.156136     0.201596     1.000000  \n",
       "max           187.000000   381.243282   474.847172   343.145356     1.000000  \n",
       "\n",
       "[8 rows x 27 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    The method used in spliting of training and testing sets is in the ratio of 80:20, which means 80% of the training data sets are used training and 20% of the data is used for testing. In this function the test size is meassured between 0 to 1, here 0.2 means 20% of the data sets. The random state controls the shuffling applied to the data before applying the split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "x = df.iloc[:, :-2]  # select all columns except the last 2\n",
    "y1 = df.iloc[:, -2]  # Select last but 2nd column\n",
    "#y1 = df[\"InvGrd\"]\n",
    "#y2 = df.iloc[:, -1]  # Selects the last column\n",
    "y2 = df[\"Rating\"]\n",
    "# Split arrays or matrices into random train and test subsets\n",
    "x_train, x_test, y1_train, y1_test, y2_train, y2_test = train_test_split(x, y1, y2, test_size=0.2, \n",
    "                                                                         random_state=97, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    We train the this model to solve regression problems where the loss function is identified by the least square function and regularization is given by the params. Alpha controls the strength of regularization. Decreasing aplha leads to lower variance and low bias and increasing alpha leads to high variance and high bias. Here we choose low alpha value. Once the reguarization is selected we then fit the regression model into it where we train the model and then we predict the value on test data sets. On analysis the accuracy was found to be 90%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Ridge model\n",
    "ridge = Ridge(alpha = 0.01, fit_intercept=True,\n",
    "    normalize=False,\n",
    "    copy_X=True,\n",
    "    max_iter=None,\n",
    "    tol=0.001,\n",
    "    solver='auto',\n",
    "    random_state=None)  # Regression model\n",
    "ridge.fit(x_train, y1_train, sample_weight=None)  # Regression fit\n",
    "y1_predict_ridge = ridge.predict(x_test) # Predicting using the test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Accuracy: 0.9\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Ridge model\n",
    "y1_predict_ridge_binary = [1 if x >= 0.5 else 0 for x in y1_predict_ridge]\n",
    "# for x in y1_predict_ridge:\n",
    "#     if x >= 0.5:\n",
    "#         1\n",
    "#     else:\n",
    "#         0\n",
    "ridge_accuracy = accuracy_score(y1_test, y1_predict_ridge_binary)\n",
    "print(\"Ridge Accuracy:\", round(ridge_accuracy,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    We train the this model to solve regression problems where the loss function is identified by the least square function and regularization is given by the params. Alpha controls the strength of regularization. Decreasing aplha leads to lower variance and low bias and increasing alpha leads to high variance and high bias. Here we choose low alpha value once again. Once the reguarization is selected we then fit the regression model into it where we train the model and then we predict the value on test data sets. On analysis the accuracy was found to be 96%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Lasso model\n",
    "lasso = Lasso(alpha=0.01, fit_intercept=True,\n",
    "    normalize=False,\n",
    "    precompute=False,\n",
    "    copy_X=True,\n",
    "    max_iter=1000,\n",
    "    tol=0.0001,\n",
    "    warm_start=False,\n",
    "    positive=False,\n",
    "    random_state=None,\n",
    "    selection='cyclic') # Regression model\n",
    "lasso.fit(x_train, y1_train) # Regression fit\n",
    "y1_predict_lasso = lasso.predict(x_test)  # Predicting using the test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Accuracy: 0.96\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Lasso model\n",
    "y1_predict_lasso_binary = [1 if x >= 0.5 else 0 for x in y1_predict_lasso]\n",
    "# for x in y1_predict_lasso:\n",
    "#     if x >= 0.5:\n",
    "#         1\n",
    "#     else:\n",
    "#         0\n",
    "lasso_accuracy = accuracy_score(y1_test, y1_predict_lasso_binary)\n",
    "print(\"Lasso Accuracy:\", round(lasso_accuracy,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    In summary to prevent any overfitting inside the model training we used lasso and ridge. On comparing the accuracy between the two regressions lasso performs better with 96% accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "########################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    In this regression model used below we tried to classify the data into 16 categories and predicted whether the firm is a investment grade or not along with its accuracy in prediction. We work with the same datset which consists of 1700 observations of 26 financial and accounting metrics for a set of firms in several different industries. The steps required here for logistic regression model are importing of libraries and loading of data sets. We then preprocess the data and then split the data into training and testing sets. We then train the model on the training data sets and test it on testing datasets to evaluate its performance. On top of this we conduct l1 and l2 regularization. Use the trained model for new predictions. The Splitting of the datasets into training and testing sets are in the ratio of 80:20. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sales/Revenues</th>\n",
       "      <th>Gross Margin</th>\n",
       "      <th>EBITDA</th>\n",
       "      <th>EBITDA Margin</th>\n",
       "      <th>Net Income Before Extras</th>\n",
       "      <th>Total Debt</th>\n",
       "      <th>Net Debt</th>\n",
       "      <th>LT Debt</th>\n",
       "      <th>ST Debt</th>\n",
       "      <th>Cash</th>\n",
       "      <th>...</th>\n",
       "      <th>Interest Coverage</th>\n",
       "      <th>Total Liquidity</th>\n",
       "      <th>Current Liquidity</th>\n",
       "      <th>Current Liabilities</th>\n",
       "      <th>EPS Before Extras</th>\n",
       "      <th>PE</th>\n",
       "      <th>ROA</th>\n",
       "      <th>ROE</th>\n",
       "      <th>InvGrd</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.005496</td>\n",
       "      <td>0.030763</td>\n",
       "      <td>0.018885</td>\n",
       "      <td>0.024515</td>\n",
       "      <td>0.146849</td>\n",
       "      <td>-0.029710</td>\n",
       "      <td>-0.019296</td>\n",
       "      <td>-0.042648</td>\n",
       "      <td>0.049875</td>\n",
       "      <td>-0.133716</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136748</td>\n",
       "      <td>0.392143</td>\n",
       "      <td>-0.184887</td>\n",
       "      <td>0.062781</td>\n",
       "      <td>0.148305</td>\n",
       "      <td>0.100409</td>\n",
       "      <td>0.163266</td>\n",
       "      <td>0.102521</td>\n",
       "      <td>1</td>\n",
       "      <td>A1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.005496</td>\n",
       "      <td>0.030763</td>\n",
       "      <td>0.088716</td>\n",
       "      <td>0.094733</td>\n",
       "      <td>0.146849</td>\n",
       "      <td>-0.029710</td>\n",
       "      <td>-0.019296</td>\n",
       "      <td>-0.042648</td>\n",
       "      <td>0.049875</td>\n",
       "      <td>-0.133716</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214657</td>\n",
       "      <td>0.392143</td>\n",
       "      <td>-0.184887</td>\n",
       "      <td>0.062781</td>\n",
       "      <td>0.148305</td>\n",
       "      <td>-0.089598</td>\n",
       "      <td>0.163266</td>\n",
       "      <td>0.102521</td>\n",
       "      <td>1</td>\n",
       "      <td>A1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.007045</td>\n",
       "      <td>0.023159</td>\n",
       "      <td>0.088716</td>\n",
       "      <td>0.096440</td>\n",
       "      <td>0.108590</td>\n",
       "      <td>0.039410</td>\n",
       "      <td>0.034268</td>\n",
       "      <td>0.009059</td>\n",
       "      <td>0.250371</td>\n",
       "      <td>0.101315</td>\n",
       "      <td>...</td>\n",
       "      <td>0.205290</td>\n",
       "      <td>0.483257</td>\n",
       "      <td>-0.017877</td>\n",
       "      <td>0.121357</td>\n",
       "      <td>0.110656</td>\n",
       "      <td>-0.045142</td>\n",
       "      <td>0.105711</td>\n",
       "      <td>0.103378</td>\n",
       "      <td>1</td>\n",
       "      <td>A1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.009396</td>\n",
       "      <td>0.028400</td>\n",
       "      <td>0.088716</td>\n",
       "      <td>0.099046</td>\n",
       "      <td>0.146137</td>\n",
       "      <td>0.030071</td>\n",
       "      <td>0.036938</td>\n",
       "      <td>-0.016964</td>\n",
       "      <td>0.356994</td>\n",
       "      <td>-0.052606</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232991</td>\n",
       "      <td>0.996955</td>\n",
       "      <td>-0.122017</td>\n",
       "      <td>0.079051</td>\n",
       "      <td>0.151639</td>\n",
       "      <td>-0.008231</td>\n",
       "      <td>0.162421</td>\n",
       "      <td>0.132295</td>\n",
       "      <td>1</td>\n",
       "      <td>A1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.009009</td>\n",
       "      <td>0.027714</td>\n",
       "      <td>0.088716</td>\n",
       "      <td>0.098611</td>\n",
       "      <td>0.123500</td>\n",
       "      <td>0.024224</td>\n",
       "      <td>0.034445</td>\n",
       "      <td>-0.034132</td>\n",
       "      <td>0.461894</td>\n",
       "      <td>-0.090869</td>\n",
       "      <td>...</td>\n",
       "      <td>0.172906</td>\n",
       "      <td>1.711426</td>\n",
       "      <td>-0.161561</td>\n",
       "      <td>0.084319</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.015528</td>\n",
       "      <td>0.156427</td>\n",
       "      <td>0.225144</td>\n",
       "      <td>1</td>\n",
       "      <td>A1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sales/Revenues  Gross Margin    EBITDA  EBITDA Margin  \\\n",
       "0       -0.005496      0.030763  0.018885       0.024515   \n",
       "1       -0.005496      0.030763  0.088716       0.094733   \n",
       "2       -0.007045      0.023159  0.088716       0.096440   \n",
       "3       -0.009396      0.028400  0.088716       0.099046   \n",
       "4       -0.009009      0.027714  0.088716       0.098611   \n",
       "\n",
       "   Net Income Before Extras  Total Debt  Net Debt   LT Debt   ST Debt  \\\n",
       "0                  0.146849   -0.029710 -0.019296 -0.042648  0.049875   \n",
       "1                  0.146849   -0.029710 -0.019296 -0.042648  0.049875   \n",
       "2                  0.108590    0.039410  0.034268  0.009059  0.250371   \n",
       "3                  0.146137    0.030071  0.036938 -0.016964  0.356994   \n",
       "4                  0.123500    0.024224  0.034445 -0.034132  0.461894   \n",
       "\n",
       "       Cash  ...  Interest Coverage  Total Liquidity  Current Liquidity  \\\n",
       "0 -0.133716  ...           0.136748         0.392143          -0.184887   \n",
       "1 -0.133716  ...           0.214657         0.392143          -0.184887   \n",
       "2  0.101315  ...           0.205290         0.483257          -0.017877   \n",
       "3 -0.052606  ...           0.232991         0.996955          -0.122017   \n",
       "4 -0.090869  ...           0.172906         1.711426          -0.161561   \n",
       "\n",
       "   Current Liabilities  EPS Before Extras        PE       ROA       ROE  \\\n",
       "0             0.062781           0.148305  0.100409  0.163266  0.102521   \n",
       "1             0.062781           0.148305 -0.089598  0.163266  0.102521   \n",
       "2             0.121357           0.110656 -0.045142  0.105711  0.103378   \n",
       "3             0.079051           0.151639 -0.008231  0.162421  0.132295   \n",
       "4             0.084319           0.130435  0.015528  0.156427  0.225144   \n",
       "\n",
       "   InvGrd  Rating  \n",
       "0       1      A1  \n",
       "1       1      A1  \n",
       "2       1      A1  \n",
       "3       1      A1  \n",
       "4       1      A1  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "\n",
    "# Loading of data\n",
    "data = pd.read_csv('MLF_GP1_CreditScore.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sales/Revenues</th>\n",
       "      <th>Gross Margin</th>\n",
       "      <th>EBITDA</th>\n",
       "      <th>EBITDA Margin</th>\n",
       "      <th>Net Income Before Extras</th>\n",
       "      <th>Total Debt</th>\n",
       "      <th>Net Debt</th>\n",
       "      <th>LT Debt</th>\n",
       "      <th>ST Debt</th>\n",
       "      <th>Cash</th>\n",
       "      <th>...</th>\n",
       "      <th>CFO</th>\n",
       "      <th>Interest Coverage</th>\n",
       "      <th>Total Liquidity</th>\n",
       "      <th>Current Liquidity</th>\n",
       "      <th>Current Liabilities</th>\n",
       "      <th>EPS Before Extras</th>\n",
       "      <th>PE</th>\n",
       "      <th>ROA</th>\n",
       "      <th>ROE</th>\n",
       "      <th>InvGrd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1700.000000</td>\n",
       "      <td>1700.000000</td>\n",
       "      <td>1700.000000</td>\n",
       "      <td>1700.000000</td>\n",
       "      <td>1700.000000</td>\n",
       "      <td>1700.000000</td>\n",
       "      <td>1700.000000</td>\n",
       "      <td>1700.000000</td>\n",
       "      <td>1700.000000</td>\n",
       "      <td>1700.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1700.000000</td>\n",
       "      <td>1700.000000</td>\n",
       "      <td>1700.000000</td>\n",
       "      <td>1700.000000</td>\n",
       "      <td>1700.000000</td>\n",
       "      <td>1700.000000</td>\n",
       "      <td>1700.000000</td>\n",
       "      <td>1700.000000</td>\n",
       "      <td>1700.000000</td>\n",
       "      <td>1700.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.050378</td>\n",
       "      <td>0.026007</td>\n",
       "      <td>0.068718</td>\n",
       "      <td>0.021074</td>\n",
       "      <td>0.123026</td>\n",
       "      <td>0.822405</td>\n",
       "      <td>-0.419810</td>\n",
       "      <td>1.255168</td>\n",
       "      <td>3.142797</td>\n",
       "      <td>0.466620</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.189317</td>\n",
       "      <td>0.298785</td>\n",
       "      <td>-0.855714</td>\n",
       "      <td>0.436002</td>\n",
       "      <td>0.072802</td>\n",
       "      <td>0.032196</td>\n",
       "      <td>0.497705</td>\n",
       "      <td>0.019394</td>\n",
       "      <td>-0.217604</td>\n",
       "      <td>0.757059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.161910</td>\n",
       "      <td>0.273768</td>\n",
       "      <td>0.237365</td>\n",
       "      <td>0.189025</td>\n",
       "      <td>14.475689</td>\n",
       "      <td>13.317075</td>\n",
       "      <td>28.385702</td>\n",
       "      <td>16.224453</td>\n",
       "      <td>51.986550</td>\n",
       "      <td>1.859494</td>\n",
       "      <td>...</td>\n",
       "      <td>5.668669</td>\n",
       "      <td>5.265291</td>\n",
       "      <td>22.926862</td>\n",
       "      <td>1.904282</td>\n",
       "      <td>0.266471</td>\n",
       "      <td>6.151994</td>\n",
       "      <td>12.102502</td>\n",
       "      <td>14.594193</td>\n",
       "      <td>15.389000</td>\n",
       "      <td>0.428986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.661715</td>\n",
       "      <td>-0.794722</td>\n",
       "      <td>-0.782254</td>\n",
       "      <td>-0.805153</td>\n",
       "      <td>-289.000000</td>\n",
       "      <td>-0.903014</td>\n",
       "      <td>-493.305578</td>\n",
       "      <td>-0.921515</td>\n",
       "      <td>-0.997692</td>\n",
       "      <td>-0.990982</td>\n",
       "      <td>...</td>\n",
       "      <td>-161.609425</td>\n",
       "      <td>-0.991976</td>\n",
       "      <td>-502.000000</td>\n",
       "      <td>-0.994141</td>\n",
       "      <td>-0.684678</td>\n",
       "      <td>-96.250000</td>\n",
       "      <td>-59.795133</td>\n",
       "      <td>-305.462167</td>\n",
       "      <td>-373.837267</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.005693</td>\n",
       "      <td>-0.020028</td>\n",
       "      <td>-0.022640</td>\n",
       "      <td>-0.042771</td>\n",
       "      <td>-0.158478</td>\n",
       "      <td>-0.076316</td>\n",
       "      <td>-0.120725</td>\n",
       "      <td>-0.094767</td>\n",
       "      <td>-0.337959</td>\n",
       "      <td>-0.195117</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.115159</td>\n",
       "      <td>-0.096996</td>\n",
       "      <td>-0.857013</td>\n",
       "      <td>-0.227327</td>\n",
       "      <td>-0.072734</td>\n",
       "      <td>-0.152894</td>\n",
       "      <td>-0.293521</td>\n",
       "      <td>-0.208483</td>\n",
       "      <td>-0.233955</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.034000</td>\n",
       "      <td>0.003403</td>\n",
       "      <td>0.049482</td>\n",
       "      <td>0.011134</td>\n",
       "      <td>0.056627</td>\n",
       "      <td>0.005886</td>\n",
       "      <td>-0.003060</td>\n",
       "      <td>-0.002078</td>\n",
       "      <td>0.043092</td>\n",
       "      <td>0.075820</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046983</td>\n",
       "      <td>0.043216</td>\n",
       "      <td>-0.229098</td>\n",
       "      <td>0.040446</td>\n",
       "      <td>0.041785</td>\n",
       "      <td>0.066027</td>\n",
       "      <td>-0.040405</td>\n",
       "      <td>-0.009403</td>\n",
       "      <td>-0.020392</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.083004</td>\n",
       "      <td>0.025595</td>\n",
       "      <td>0.124533</td>\n",
       "      <td>0.060566</td>\n",
       "      <td>0.222219</td>\n",
       "      <td>0.136449</td>\n",
       "      <td>0.160251</td>\n",
       "      <td>0.174735</td>\n",
       "      <td>0.649475</td>\n",
       "      <td>0.483113</td>\n",
       "      <td>...</td>\n",
       "      <td>0.216432</td>\n",
       "      <td>0.177340</td>\n",
       "      <td>0.512778</td>\n",
       "      <td>0.416067</td>\n",
       "      <td>0.161215</td>\n",
       "      <td>0.236046</td>\n",
       "      <td>0.168897</td>\n",
       "      <td>0.156136</td>\n",
       "      <td>0.201596</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.277229</td>\n",
       "      <td>3.202713</td>\n",
       "      <td>3.542425</td>\n",
       "      <td>4.141182</td>\n",
       "      <td>478.280075</td>\n",
       "      <td>281.604237</td>\n",
       "      <td>865.194595</td>\n",
       "      <td>289.388178</td>\n",
       "      <td>2038.000000</td>\n",
       "      <td>36.980037</td>\n",
       "      <td>...</td>\n",
       "      <td>13.005788</td>\n",
       "      <td>182.131887</td>\n",
       "      <td>280.138728</td>\n",
       "      <td>34.372455</td>\n",
       "      <td>4.194381</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>381.243282</td>\n",
       "      <td>474.847172</td>\n",
       "      <td>343.145356</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Sales/Revenues  Gross Margin       EBITDA  EBITDA Margin  \\\n",
       "count     1700.000000   1700.000000  1700.000000    1700.000000   \n",
       "mean         0.050378      0.026007     0.068718       0.021074   \n",
       "std          0.161910      0.273768     0.237365       0.189025   \n",
       "min         -0.661715     -0.794722    -0.782254      -0.805153   \n",
       "25%         -0.005693     -0.020028    -0.022640      -0.042771   \n",
       "50%          0.034000      0.003403     0.049482       0.011134   \n",
       "75%          0.083004      0.025595     0.124533       0.060566   \n",
       "max          2.277229      3.202713     3.542425       4.141182   \n",
       "\n",
       "       Net Income Before Extras   Total Debt     Net Debt      LT Debt  \\\n",
       "count               1700.000000  1700.000000  1700.000000  1700.000000   \n",
       "mean                   0.123026     0.822405    -0.419810     1.255168   \n",
       "std                   14.475689    13.317075    28.385702    16.224453   \n",
       "min                 -289.000000    -0.903014  -493.305578    -0.921515   \n",
       "25%                   -0.158478    -0.076316    -0.120725    -0.094767   \n",
       "50%                    0.056627     0.005886    -0.003060    -0.002078   \n",
       "75%                    0.222219     0.136449     0.160251     0.174735   \n",
       "max                  478.280075   281.604237   865.194595   289.388178   \n",
       "\n",
       "           ST Debt         Cash  ...          CFO  Interest Coverage  \\\n",
       "count  1700.000000  1700.000000  ...  1700.000000        1700.000000   \n",
       "mean      3.142797     0.466620  ...    -0.189317           0.298785   \n",
       "std      51.986550     1.859494  ...     5.668669           5.265291   \n",
       "min      -0.997692    -0.990982  ...  -161.609425          -0.991976   \n",
       "25%      -0.337959    -0.195117  ...    -0.115159          -0.096996   \n",
       "50%       0.043092     0.075820  ...     0.046983           0.043216   \n",
       "75%       0.649475     0.483113  ...     0.216432           0.177340   \n",
       "max    2038.000000    36.980037  ...    13.005788         182.131887   \n",
       "\n",
       "       Total Liquidity  Current Liquidity  Current Liabilities  \\\n",
       "count      1700.000000        1700.000000          1700.000000   \n",
       "mean         -0.855714           0.436002             0.072802   \n",
       "std          22.926862           1.904282             0.266471   \n",
       "min        -502.000000          -0.994141            -0.684678   \n",
       "25%          -0.857013          -0.227327            -0.072734   \n",
       "50%          -0.229098           0.040446             0.041785   \n",
       "75%           0.512778           0.416067             0.161215   \n",
       "max         280.138728          34.372455             4.194381   \n",
       "\n",
       "       EPS Before Extras           PE          ROA          ROE       InvGrd  \n",
       "count        1700.000000  1700.000000  1700.000000  1700.000000  1700.000000  \n",
       "mean            0.032196     0.497705     0.019394    -0.217604     0.757059  \n",
       "std             6.151994    12.102502    14.594193    15.389000     0.428986  \n",
       "min           -96.250000   -59.795133  -305.462167  -373.837267     0.000000  \n",
       "25%            -0.152894    -0.293521    -0.208483    -0.233955     1.000000  \n",
       "50%             0.066027    -0.040405    -0.009403    -0.020392     1.000000  \n",
       "75%             0.236046     0.168897     0.156136     0.201596     1.000000  \n",
       "max           187.000000   381.243282   474.847172   343.145356     1.000000  \n",
       "\n",
       "[8 rows x 27 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    We split the data into training and testing sets, we then do data preprocessing where 80% of the training data sets are used for training and 20% of the data is used for testing. We then fit a logistic regression model with L1 regularization to the training data. We used liblinear solver and penalty l1 to predict the accuracy of the model. Upon prediction the acciracy of the model was found to be 76.47% "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "x_train = train_data.iloc[:, :-2]  # select all columns except the last 2\n",
    "y_train = train_data.iloc[:, -2]   # Select last but 2nd column\n",
    "\n",
    "x_test = test_data.iloc[:, :-2]   # select all columns except the last 2\n",
    "y_test = test_data.iloc[:, -2]    # Select last but 2nd column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(penalty='l1', solver='liblinear')"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data preprocessing\n",
    "\n",
    "# Fit a logistic regression model with L1 regularization to the training data\n",
    "Ridge = LogisticRegression(penalty='l1',solver='liblinear', max_iter=100,\n",
    "    multi_class='auto',\n",
    "    verbose=0,\n",
    "    warm_start=False,\n",
    "    n_jobs=None,\n",
    "    l1_ratio=None)   # Logistic regression classifier\n",
    "Ridge.fit(x_train, y_train)  # Regression fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model prediction\n",
    "p_y = Ridge.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Accuracy: 0.7647\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, p_y)         # L1 accuracy\n",
    "print(\"Ridge Accuracy:\", round(accuracy,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(solver='newton-cg')"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data pre processing\n",
    "\n",
    "# Fit a logistic regression model with L2 regularization to the training data\n",
    "Lasso = LogisticRegression(penalty='l2',solver='newton-cg',\n",
    "                           max_iter=100,\n",
    "    multi_class='auto',\n",
    "    verbose=0,\n",
    "    warm_start=False,\n",
    "    n_jobs=None,\n",
    "    l1_ratio=None)    # Logistic regression classifier\n",
    "Lasso.fit(x_train, y_train)  # Regression fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso prediction\n",
    "p_y = Lasso.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Accuracy: 0.7676\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, p_y)      # check the accuracy score\n",
    "print(\"Lasso Accuracy:\", round(accuracy,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Upon splitting up of data and conducting l1 regularization technique to find the best possible fit, here we find the accuracy of the Lasso regularisation where we use a different solver known as newton-cg to improve the accuracy of the model. Upon fitting of data into the training model we then predict that the accuracy of the model improved marginally. By this we can conclude that both the regularization predict that a firm is of a investment grade. The accuracy in predicting such a grade is 76.6% in both Rigid and lasso regularization technique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##########################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Neural network learning based aprroaches are to classify firms rating to any one of the categories and check if it is an investment grade. The datset consists of 1700 observations of 26 financial and accounting metrics for a set of firms in several different industries. The steps followed here are importing of libraries and loading of data sets. Here we will preprocess the data by removing NA's or converting categorical to numeric.  We then split the data into training and testing sets. We then train the model on the training data sets and test it on testing datasets to evaluate its performance. Use the trained neural network model for new predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sales/Revenues</th>\n",
       "      <th>Gross Margin</th>\n",
       "      <th>EBITDA</th>\n",
       "      <th>EBITDA Margin</th>\n",
       "      <th>Net Income Before Extras</th>\n",
       "      <th>Total Debt</th>\n",
       "      <th>Net Debt</th>\n",
       "      <th>LT Debt</th>\n",
       "      <th>ST Debt</th>\n",
       "      <th>Cash</th>\n",
       "      <th>...</th>\n",
       "      <th>Interest Coverage</th>\n",
       "      <th>Total Liquidity</th>\n",
       "      <th>Current Liquidity</th>\n",
       "      <th>Current Liabilities</th>\n",
       "      <th>EPS Before Extras</th>\n",
       "      <th>PE</th>\n",
       "      <th>ROA</th>\n",
       "      <th>ROE</th>\n",
       "      <th>InvGrd</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.005496</td>\n",
       "      <td>0.030763</td>\n",
       "      <td>0.018885</td>\n",
       "      <td>0.024515</td>\n",
       "      <td>0.146849</td>\n",
       "      <td>-0.029710</td>\n",
       "      <td>-0.019296</td>\n",
       "      <td>-0.042648</td>\n",
       "      <td>0.049875</td>\n",
       "      <td>-0.133716</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136748</td>\n",
       "      <td>0.392143</td>\n",
       "      <td>-0.184887</td>\n",
       "      <td>0.062781</td>\n",
       "      <td>0.148305</td>\n",
       "      <td>0.100409</td>\n",
       "      <td>0.163266</td>\n",
       "      <td>0.102521</td>\n",
       "      <td>1</td>\n",
       "      <td>A1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.005496</td>\n",
       "      <td>0.030763</td>\n",
       "      <td>0.088716</td>\n",
       "      <td>0.094733</td>\n",
       "      <td>0.146849</td>\n",
       "      <td>-0.029710</td>\n",
       "      <td>-0.019296</td>\n",
       "      <td>-0.042648</td>\n",
       "      <td>0.049875</td>\n",
       "      <td>-0.133716</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214657</td>\n",
       "      <td>0.392143</td>\n",
       "      <td>-0.184887</td>\n",
       "      <td>0.062781</td>\n",
       "      <td>0.148305</td>\n",
       "      <td>-0.089598</td>\n",
       "      <td>0.163266</td>\n",
       "      <td>0.102521</td>\n",
       "      <td>1</td>\n",
       "      <td>A1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.007045</td>\n",
       "      <td>0.023159</td>\n",
       "      <td>0.088716</td>\n",
       "      <td>0.096440</td>\n",
       "      <td>0.108590</td>\n",
       "      <td>0.039410</td>\n",
       "      <td>0.034268</td>\n",
       "      <td>0.009059</td>\n",
       "      <td>0.250371</td>\n",
       "      <td>0.101315</td>\n",
       "      <td>...</td>\n",
       "      <td>0.205290</td>\n",
       "      <td>0.483257</td>\n",
       "      <td>-0.017877</td>\n",
       "      <td>0.121357</td>\n",
       "      <td>0.110656</td>\n",
       "      <td>-0.045142</td>\n",
       "      <td>0.105711</td>\n",
       "      <td>0.103378</td>\n",
       "      <td>1</td>\n",
       "      <td>A1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.009396</td>\n",
       "      <td>0.028400</td>\n",
       "      <td>0.088716</td>\n",
       "      <td>0.099046</td>\n",
       "      <td>0.146137</td>\n",
       "      <td>0.030071</td>\n",
       "      <td>0.036938</td>\n",
       "      <td>-0.016964</td>\n",
       "      <td>0.356994</td>\n",
       "      <td>-0.052606</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232991</td>\n",
       "      <td>0.996955</td>\n",
       "      <td>-0.122017</td>\n",
       "      <td>0.079051</td>\n",
       "      <td>0.151639</td>\n",
       "      <td>-0.008231</td>\n",
       "      <td>0.162421</td>\n",
       "      <td>0.132295</td>\n",
       "      <td>1</td>\n",
       "      <td>A1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.009009</td>\n",
       "      <td>0.027714</td>\n",
       "      <td>0.088716</td>\n",
       "      <td>0.098611</td>\n",
       "      <td>0.123500</td>\n",
       "      <td>0.024224</td>\n",
       "      <td>0.034445</td>\n",
       "      <td>-0.034132</td>\n",
       "      <td>0.461894</td>\n",
       "      <td>-0.090869</td>\n",
       "      <td>...</td>\n",
       "      <td>0.172906</td>\n",
       "      <td>1.711426</td>\n",
       "      <td>-0.161561</td>\n",
       "      <td>0.084319</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.015528</td>\n",
       "      <td>0.156427</td>\n",
       "      <td>0.225144</td>\n",
       "      <td>1</td>\n",
       "      <td>A1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sales/Revenues  Gross Margin    EBITDA  EBITDA Margin  \\\n",
       "0       -0.005496      0.030763  0.018885       0.024515   \n",
       "1       -0.005496      0.030763  0.088716       0.094733   \n",
       "2       -0.007045      0.023159  0.088716       0.096440   \n",
       "3       -0.009396      0.028400  0.088716       0.099046   \n",
       "4       -0.009009      0.027714  0.088716       0.098611   \n",
       "\n",
       "   Net Income Before Extras  Total Debt  Net Debt   LT Debt   ST Debt  \\\n",
       "0                  0.146849   -0.029710 -0.019296 -0.042648  0.049875   \n",
       "1                  0.146849   -0.029710 -0.019296 -0.042648  0.049875   \n",
       "2                  0.108590    0.039410  0.034268  0.009059  0.250371   \n",
       "3                  0.146137    0.030071  0.036938 -0.016964  0.356994   \n",
       "4                  0.123500    0.024224  0.034445 -0.034132  0.461894   \n",
       "\n",
       "       Cash  ...  Interest Coverage  Total Liquidity  Current Liquidity  \\\n",
       "0 -0.133716  ...           0.136748         0.392143          -0.184887   \n",
       "1 -0.133716  ...           0.214657         0.392143          -0.184887   \n",
       "2  0.101315  ...           0.205290         0.483257          -0.017877   \n",
       "3 -0.052606  ...           0.232991         0.996955          -0.122017   \n",
       "4 -0.090869  ...           0.172906         1.711426          -0.161561   \n",
       "\n",
       "   Current Liabilities  EPS Before Extras        PE       ROA       ROE  \\\n",
       "0             0.062781           0.148305  0.100409  0.163266  0.102521   \n",
       "1             0.062781           0.148305 -0.089598  0.163266  0.102521   \n",
       "2             0.121357           0.110656 -0.045142  0.105711  0.103378   \n",
       "3             0.079051           0.151639 -0.008231  0.162421  0.132295   \n",
       "4             0.084319           0.130435  0.015528  0.156427  0.225144   \n",
       "\n",
       "   InvGrd  Rating  \n",
       "0       1      A1  \n",
       "1       1      A1  \n",
       "2       1      A1  \n",
       "3       1      A1  \n",
       "4       1      A1  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading of dataset\n",
    "data = pd.read_csv(\"MLF_GP1_CreditScore.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sales/Revenues</th>\n",
       "      <th>Gross Margin</th>\n",
       "      <th>EBITDA</th>\n",
       "      <th>EBITDA Margin</th>\n",
       "      <th>Net Income Before Extras</th>\n",
       "      <th>Total Debt</th>\n",
       "      <th>Net Debt</th>\n",
       "      <th>LT Debt</th>\n",
       "      <th>ST Debt</th>\n",
       "      <th>Cash</th>\n",
       "      <th>...</th>\n",
       "      <th>CFO</th>\n",
       "      <th>Interest Coverage</th>\n",
       "      <th>Total Liquidity</th>\n",
       "      <th>Current Liquidity</th>\n",
       "      <th>Current Liabilities</th>\n",
       "      <th>EPS Before Extras</th>\n",
       "      <th>PE</th>\n",
       "      <th>ROA</th>\n",
       "      <th>ROE</th>\n",
       "      <th>InvGrd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1700.000000</td>\n",
       "      <td>1700.000000</td>\n",
       "      <td>1700.000000</td>\n",
       "      <td>1700.000000</td>\n",
       "      <td>1700.000000</td>\n",
       "      <td>1700.000000</td>\n",
       "      <td>1700.000000</td>\n",
       "      <td>1700.000000</td>\n",
       "      <td>1700.000000</td>\n",
       "      <td>1700.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1700.000000</td>\n",
       "      <td>1700.000000</td>\n",
       "      <td>1700.000000</td>\n",
       "      <td>1700.000000</td>\n",
       "      <td>1700.000000</td>\n",
       "      <td>1700.000000</td>\n",
       "      <td>1700.000000</td>\n",
       "      <td>1700.000000</td>\n",
       "      <td>1700.000000</td>\n",
       "      <td>1700.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.050378</td>\n",
       "      <td>0.026007</td>\n",
       "      <td>0.068718</td>\n",
       "      <td>0.021074</td>\n",
       "      <td>0.123026</td>\n",
       "      <td>0.822405</td>\n",
       "      <td>-0.419810</td>\n",
       "      <td>1.255168</td>\n",
       "      <td>3.142797</td>\n",
       "      <td>0.466620</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.189317</td>\n",
       "      <td>0.298785</td>\n",
       "      <td>-0.855714</td>\n",
       "      <td>0.436002</td>\n",
       "      <td>0.072802</td>\n",
       "      <td>0.032196</td>\n",
       "      <td>0.497705</td>\n",
       "      <td>0.019394</td>\n",
       "      <td>-0.217604</td>\n",
       "      <td>0.757059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.161910</td>\n",
       "      <td>0.273768</td>\n",
       "      <td>0.237365</td>\n",
       "      <td>0.189025</td>\n",
       "      <td>14.475689</td>\n",
       "      <td>13.317075</td>\n",
       "      <td>28.385702</td>\n",
       "      <td>16.224453</td>\n",
       "      <td>51.986550</td>\n",
       "      <td>1.859494</td>\n",
       "      <td>...</td>\n",
       "      <td>5.668669</td>\n",
       "      <td>5.265291</td>\n",
       "      <td>22.926862</td>\n",
       "      <td>1.904282</td>\n",
       "      <td>0.266471</td>\n",
       "      <td>6.151994</td>\n",
       "      <td>12.102502</td>\n",
       "      <td>14.594193</td>\n",
       "      <td>15.389000</td>\n",
       "      <td>0.428986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.661715</td>\n",
       "      <td>-0.794722</td>\n",
       "      <td>-0.782254</td>\n",
       "      <td>-0.805153</td>\n",
       "      <td>-289.000000</td>\n",
       "      <td>-0.903014</td>\n",
       "      <td>-493.305578</td>\n",
       "      <td>-0.921515</td>\n",
       "      <td>-0.997692</td>\n",
       "      <td>-0.990982</td>\n",
       "      <td>...</td>\n",
       "      <td>-161.609425</td>\n",
       "      <td>-0.991976</td>\n",
       "      <td>-502.000000</td>\n",
       "      <td>-0.994141</td>\n",
       "      <td>-0.684678</td>\n",
       "      <td>-96.250000</td>\n",
       "      <td>-59.795133</td>\n",
       "      <td>-305.462167</td>\n",
       "      <td>-373.837267</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.005693</td>\n",
       "      <td>-0.020028</td>\n",
       "      <td>-0.022640</td>\n",
       "      <td>-0.042771</td>\n",
       "      <td>-0.158478</td>\n",
       "      <td>-0.076316</td>\n",
       "      <td>-0.120725</td>\n",
       "      <td>-0.094767</td>\n",
       "      <td>-0.337959</td>\n",
       "      <td>-0.195117</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.115159</td>\n",
       "      <td>-0.096996</td>\n",
       "      <td>-0.857013</td>\n",
       "      <td>-0.227327</td>\n",
       "      <td>-0.072734</td>\n",
       "      <td>-0.152894</td>\n",
       "      <td>-0.293521</td>\n",
       "      <td>-0.208483</td>\n",
       "      <td>-0.233955</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.034000</td>\n",
       "      <td>0.003403</td>\n",
       "      <td>0.049482</td>\n",
       "      <td>0.011134</td>\n",
       "      <td>0.056627</td>\n",
       "      <td>0.005886</td>\n",
       "      <td>-0.003060</td>\n",
       "      <td>-0.002078</td>\n",
       "      <td>0.043092</td>\n",
       "      <td>0.075820</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046983</td>\n",
       "      <td>0.043216</td>\n",
       "      <td>-0.229098</td>\n",
       "      <td>0.040446</td>\n",
       "      <td>0.041785</td>\n",
       "      <td>0.066027</td>\n",
       "      <td>-0.040405</td>\n",
       "      <td>-0.009403</td>\n",
       "      <td>-0.020392</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.083004</td>\n",
       "      <td>0.025595</td>\n",
       "      <td>0.124533</td>\n",
       "      <td>0.060566</td>\n",
       "      <td>0.222219</td>\n",
       "      <td>0.136449</td>\n",
       "      <td>0.160251</td>\n",
       "      <td>0.174735</td>\n",
       "      <td>0.649475</td>\n",
       "      <td>0.483113</td>\n",
       "      <td>...</td>\n",
       "      <td>0.216432</td>\n",
       "      <td>0.177340</td>\n",
       "      <td>0.512778</td>\n",
       "      <td>0.416067</td>\n",
       "      <td>0.161215</td>\n",
       "      <td>0.236046</td>\n",
       "      <td>0.168897</td>\n",
       "      <td>0.156136</td>\n",
       "      <td>0.201596</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.277229</td>\n",
       "      <td>3.202713</td>\n",
       "      <td>3.542425</td>\n",
       "      <td>4.141182</td>\n",
       "      <td>478.280075</td>\n",
       "      <td>281.604237</td>\n",
       "      <td>865.194595</td>\n",
       "      <td>289.388178</td>\n",
       "      <td>2038.000000</td>\n",
       "      <td>36.980037</td>\n",
       "      <td>...</td>\n",
       "      <td>13.005788</td>\n",
       "      <td>182.131887</td>\n",
       "      <td>280.138728</td>\n",
       "      <td>34.372455</td>\n",
       "      <td>4.194381</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>381.243282</td>\n",
       "      <td>474.847172</td>\n",
       "      <td>343.145356</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Sales/Revenues  Gross Margin       EBITDA  EBITDA Margin  \\\n",
       "count     1700.000000   1700.000000  1700.000000    1700.000000   \n",
       "mean         0.050378      0.026007     0.068718       0.021074   \n",
       "std          0.161910      0.273768     0.237365       0.189025   \n",
       "min         -0.661715     -0.794722    -0.782254      -0.805153   \n",
       "25%         -0.005693     -0.020028    -0.022640      -0.042771   \n",
       "50%          0.034000      0.003403     0.049482       0.011134   \n",
       "75%          0.083004      0.025595     0.124533       0.060566   \n",
       "max          2.277229      3.202713     3.542425       4.141182   \n",
       "\n",
       "       Net Income Before Extras   Total Debt     Net Debt      LT Debt  \\\n",
       "count               1700.000000  1700.000000  1700.000000  1700.000000   \n",
       "mean                   0.123026     0.822405    -0.419810     1.255168   \n",
       "std                   14.475689    13.317075    28.385702    16.224453   \n",
       "min                 -289.000000    -0.903014  -493.305578    -0.921515   \n",
       "25%                   -0.158478    -0.076316    -0.120725    -0.094767   \n",
       "50%                    0.056627     0.005886    -0.003060    -0.002078   \n",
       "75%                    0.222219     0.136449     0.160251     0.174735   \n",
       "max                  478.280075   281.604237   865.194595   289.388178   \n",
       "\n",
       "           ST Debt         Cash  ...          CFO  Interest Coverage  \\\n",
       "count  1700.000000  1700.000000  ...  1700.000000        1700.000000   \n",
       "mean      3.142797     0.466620  ...    -0.189317           0.298785   \n",
       "std      51.986550     1.859494  ...     5.668669           5.265291   \n",
       "min      -0.997692    -0.990982  ...  -161.609425          -0.991976   \n",
       "25%      -0.337959    -0.195117  ...    -0.115159          -0.096996   \n",
       "50%       0.043092     0.075820  ...     0.046983           0.043216   \n",
       "75%       0.649475     0.483113  ...     0.216432           0.177340   \n",
       "max    2038.000000    36.980037  ...    13.005788         182.131887   \n",
       "\n",
       "       Total Liquidity  Current Liquidity  Current Liabilities  \\\n",
       "count      1700.000000        1700.000000          1700.000000   \n",
       "mean         -0.855714           0.436002             0.072802   \n",
       "std          22.926862           1.904282             0.266471   \n",
       "min        -502.000000          -0.994141            -0.684678   \n",
       "25%          -0.857013          -0.227327            -0.072734   \n",
       "50%          -0.229098           0.040446             0.041785   \n",
       "75%           0.512778           0.416067             0.161215   \n",
       "max         280.138728          34.372455             4.194381   \n",
       "\n",
       "       EPS Before Extras           PE          ROA          ROE       InvGrd  \n",
       "count        1700.000000  1700.000000  1700.000000  1700.000000  1700.000000  \n",
       "mean            0.032196     0.497705     0.019394    -0.217604     0.757059  \n",
       "std             6.151994    12.102502    14.594193    15.389000     0.428986  \n",
       "min           -96.250000   -59.795133  -305.462167  -373.837267     0.000000  \n",
       "25%            -0.152894    -0.293521    -0.208483    -0.233955     1.000000  \n",
       "50%             0.066027    -0.040405    -0.009403    -0.020392     1.000000  \n",
       "75%             0.236046     0.168897     0.156136     0.201596     1.000000  \n",
       "max           187.000000   381.243282   474.847172   343.145356     1.000000  \n",
       "\n",
       "[8 rows x 27 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting factoral to numeric\n",
    "e = LabelEncoder()\n",
    "data[\"Rating\"] = e.fit_transform(data[\"Rating\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    We split the data into training and testing sets, we then do data preprocessing where 80% of the training data sets are used for training and 20% of the data is used for testing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-126-8c886d07b54b>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-126-8c886d07b54b>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    train_data, test_data = train_test_split(data, test_size=0.2, random_state=42, , shuffle=False)\u001b[0m\n\u001b[1;37m                                                                                   ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Spliting the data into training and testing\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42, , shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locating the variables \n",
    "x_train = train_data.iloc[:, :-2].values       # select all columns except the last 2\n",
    "y_train = train_data.iloc[:, -2:].values[:, 0]  # Select last but 2nd column\n",
    "x_test = test_data.iloc[:, :-2].values          # select all columns except the last 2\n",
    "y_test = test_data.iloc[:, -2:].values[:, 0]    # Selects last 2 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining model architecture\n",
    "m = Sequential() # defined from keras model \n",
    "m.add(Dense(units=64, activation=\"relu\", input_dim=x_train.shape[1]))   # dense by keras layer\n",
    "m.add(Dense(units=32, activation=\"relu\"))                     # dense by keras layer\n",
    "m.add(Dense(units=16, activation=\"softmax\"))                   # dense by keras layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model compilation\n",
    "m.compile(optimizer=\"rmsprop\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"], loss_weights=None,\n",
    "          weighted_metrics=None, run_eagerly=None, steps_per_execution=None,\n",
    "    jit_compile=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "17/17 [==============================] - 1s 30ms/step - loss: 0.0749 - accuracy: 0.9853 - val_loss: 0.6191 - val_accuracy: 0.8382\n",
      "Epoch 2/100\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0477 - accuracy: 0.9871 - val_loss: 0.6403 - val_accuracy: 0.8382\n",
      "Epoch 3/100\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0504 - accuracy: 0.9871 - val_loss: 0.6989 - val_accuracy: 0.8419\n",
      "Epoch 4/100\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0538 - accuracy: 0.9853 - val_loss: 0.7043 - val_accuracy: 0.8456\n",
      "Epoch 5/100\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0524 - accuracy: 0.9881 - val_loss: 0.6519 - val_accuracy: 0.8529\n",
      "Epoch 6/100\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0559 - accuracy: 0.9871 - val_loss: 0.7686 - val_accuracy: 0.8493\n",
      "Epoch 7/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0608 - accuracy: 0.9871 - val_loss: 0.6607 - val_accuracy: 0.8382\n",
      "Epoch 8/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0397 - accuracy: 0.9926 - val_loss: 0.6774 - val_accuracy: 0.8346\n",
      "Epoch 9/100\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0561 - accuracy: 0.9881 - val_loss: 0.6988 - val_accuracy: 0.8346\n",
      "Epoch 10/100\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0413 - accuracy: 0.9890 - val_loss: 0.6850 - val_accuracy: 0.8309\n",
      "Epoch 11/100\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0526 - accuracy: 0.9853 - val_loss: 0.6210 - val_accuracy: 0.8456\n",
      "Epoch 12/100\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0411 - accuracy: 0.9899 - val_loss: 0.7044 - val_accuracy: 0.8382\n",
      "Epoch 13/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0814 - accuracy: 0.9890 - val_loss: 0.7293 - val_accuracy: 0.8419\n",
      "Epoch 14/100\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0454 - accuracy: 0.9917 - val_loss: 0.7087 - val_accuracy: 0.8235\n",
      "Epoch 15/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0520 - accuracy: 0.9890 - val_loss: 0.6475 - val_accuracy: 0.8456\n",
      "Epoch 16/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0385 - accuracy: 0.9917 - val_loss: 0.6657 - val_accuracy: 0.8419\n",
      "Epoch 17/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0587 - accuracy: 0.9890 - val_loss: 0.6788 - val_accuracy: 0.8456\n",
      "Epoch 18/100\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0465 - accuracy: 0.9871 - val_loss: 0.6920 - val_accuracy: 0.8456\n",
      "Epoch 19/100\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0393 - accuracy: 0.9908 - val_loss: 0.7648 - val_accuracy: 0.8493\n",
      "Epoch 20/100\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0438 - accuracy: 0.9899 - val_loss: 0.6374 - val_accuracy: 0.8346\n",
      "Epoch 21/100\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0417 - accuracy: 0.9917 - val_loss: 0.7307 - val_accuracy: 0.8346\n",
      "Epoch 22/100\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0508 - accuracy: 0.9890 - val_loss: 0.6603 - val_accuracy: 0.8529\n",
      "Epoch 23/100\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0544 - accuracy: 0.9890 - val_loss: 0.6836 - val_accuracy: 0.8419\n",
      "Epoch 24/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0372 - accuracy: 0.9917 - val_loss: 0.7023 - val_accuracy: 0.8346\n",
      "Epoch 25/100\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0431 - accuracy: 0.9890 - val_loss: 0.6880 - val_accuracy: 0.8419\n",
      "Epoch 26/100\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0452 - accuracy: 0.9890 - val_loss: 0.7370 - val_accuracy: 0.8382\n",
      "Epoch 27/100\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0405 - accuracy: 0.9917 - val_loss: 0.7161 - val_accuracy: 0.8346\n",
      "Epoch 28/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0395 - accuracy: 0.9926 - val_loss: 0.6951 - val_accuracy: 0.8493\n",
      "Epoch 29/100\n",
      "17/17 [==============================] - 0s 14ms/step - loss: 0.0303 - accuracy: 0.9954 - val_loss: 0.7280 - val_accuracy: 0.8382\n",
      "Epoch 30/100\n",
      "17/17 [==============================] - 0s 14ms/step - loss: 0.0375 - accuracy: 0.9936 - val_loss: 0.7452 - val_accuracy: 0.8346\n",
      "Epoch 31/100\n",
      "17/17 [==============================] - 0s 14ms/step - loss: 0.0554 - accuracy: 0.9881 - val_loss: 0.6881 - val_accuracy: 0.8346\n",
      "Epoch 32/100\n",
      "17/17 [==============================] - 0s 14ms/step - loss: 0.0362 - accuracy: 0.9936 - val_loss: 0.7152 - val_accuracy: 0.8346\n",
      "Epoch 33/100\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 0.0434 - accuracy: 0.9890 - val_loss: 0.7654 - val_accuracy: 0.8382\n",
      "Epoch 34/100\n",
      "17/17 [==============================] - 0s 14ms/step - loss: 0.0458 - accuracy: 0.9926 - val_loss: 0.7438 - val_accuracy: 0.8493\n",
      "Epoch 35/100\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0339 - accuracy: 0.9945 - val_loss: 0.7211 - val_accuracy: 0.8456\n",
      "Epoch 36/100\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0377 - accuracy: 0.9926 - val_loss: 0.6964 - val_accuracy: 0.8493\n",
      "Epoch 37/100\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 0.0651 - accuracy: 0.9954 - val_loss: 0.7602 - val_accuracy: 0.8456\n",
      "Epoch 38/100\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.0339 - accuracy: 0.9917 - val_loss: 0.7735 - val_accuracy: 0.8419\n",
      "Epoch 39/100\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0332 - accuracy: 0.9926 - val_loss: 0.7355 - val_accuracy: 0.8419\n",
      "Epoch 40/100\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0507 - accuracy: 0.9871 - val_loss: 0.8109 - val_accuracy: 0.8346\n",
      "Epoch 41/100\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 0.0356 - accuracy: 0.9926 - val_loss: 0.6874 - val_accuracy: 0.8493\n",
      "Epoch 42/100\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0317 - accuracy: 0.9936 - val_loss: 0.6893 - val_accuracy: 0.8456\n",
      "Epoch 43/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0314 - accuracy: 0.9945 - val_loss: 0.7940 - val_accuracy: 0.8346\n",
      "Epoch 44/100\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0377 - accuracy: 0.9945 - val_loss: 0.8453 - val_accuracy: 0.8309\n",
      "Epoch 45/100\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0374 - accuracy: 0.9926 - val_loss: 0.7136 - val_accuracy: 0.8309\n",
      "Epoch 46/100\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0355 - accuracy: 0.9945 - val_loss: 0.7217 - val_accuracy: 0.8419\n",
      "Epoch 47/100\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0378 - accuracy: 0.9926 - val_loss: 0.7814 - val_accuracy: 0.8346\n",
      "Epoch 48/100\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0353 - accuracy: 0.9908 - val_loss: 0.8062 - val_accuracy: 0.8346\n",
      "Epoch 49/100\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0419 - accuracy: 0.9936 - val_loss: 0.7407 - val_accuracy: 0.8529\n",
      "Epoch 50/100\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0290 - accuracy: 0.9954 - val_loss: 0.7606 - val_accuracy: 0.8382\n",
      "Epoch 51/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0302 - accuracy: 0.9945 - val_loss: 0.7300 - val_accuracy: 0.8566\n",
      "Epoch 52/100\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0311 - accuracy: 0.9945 - val_loss: 0.8233 - val_accuracy: 0.8529\n",
      "Epoch 53/100\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0335 - accuracy: 0.9945 - val_loss: 0.7739 - val_accuracy: 0.8419\n",
      "Epoch 54/100\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0355 - accuracy: 0.9945 - val_loss: 0.7558 - val_accuracy: 0.8382\n",
      "Epoch 55/100\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0341 - accuracy: 0.9936 - val_loss: 0.7687 - val_accuracy: 0.8529\n",
      "Epoch 56/100\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0412 - accuracy: 0.9917 - val_loss: 0.7513 - val_accuracy: 0.8640\n",
      "Epoch 57/100\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0240 - accuracy: 0.9972 - val_loss: 0.7687 - val_accuracy: 0.8493\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0235 - accuracy: 0.9972 - val_loss: 0.7884 - val_accuracy: 0.8456\n",
      "Epoch 59/100\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0446 - accuracy: 0.9899 - val_loss: 0.7471 - val_accuracy: 0.8382\n",
      "Epoch 60/100\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0332 - accuracy: 0.9963 - val_loss: 0.7790 - val_accuracy: 0.8419\n",
      "Epoch 61/100\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0246 - accuracy: 0.9963 - val_loss: 0.7725 - val_accuracy: 0.8346\n",
      "Epoch 62/100\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0311 - accuracy: 0.9917 - val_loss: 0.7248 - val_accuracy: 0.8346\n",
      "Epoch 63/100\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0255 - accuracy: 0.9963 - val_loss: 0.8042 - val_accuracy: 0.8382\n",
      "Epoch 64/100\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0253 - accuracy: 0.9954 - val_loss: 0.7402 - val_accuracy: 0.8419\n",
      "Epoch 65/100\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0224 - accuracy: 0.9982 - val_loss: 0.8349 - val_accuracy: 0.8493\n",
      "Epoch 66/100\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0359 - accuracy: 0.9926 - val_loss: 0.7716 - val_accuracy: 0.8382\n",
      "Epoch 67/100\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0272 - accuracy: 0.9954 - val_loss: 0.8120 - val_accuracy: 0.8382\n",
      "Epoch 68/100\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0417 - accuracy: 0.9954 - val_loss: 0.8492 - val_accuracy: 0.8566\n",
      "Epoch 69/100\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0219 - accuracy: 0.9972 - val_loss: 0.8517 - val_accuracy: 0.8309\n",
      "Epoch 70/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0293 - accuracy: 0.9936 - val_loss: 0.7815 - val_accuracy: 0.8382\n",
      "Epoch 71/100\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 0.0417 - accuracy: 0.9963 - val_loss: 0.8026 - val_accuracy: 0.8456\n",
      "Epoch 72/100\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0201 - accuracy: 0.9972 - val_loss: 0.8382 - val_accuracy: 0.8382\n",
      "Epoch 73/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0430 - accuracy: 0.9954 - val_loss: 0.8821 - val_accuracy: 0.8493\n",
      "Epoch 74/100\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0304 - accuracy: 0.9936 - val_loss: 0.8116 - val_accuracy: 0.8456\n",
      "Epoch 75/100\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0278 - accuracy: 0.9926 - val_loss: 0.8261 - val_accuracy: 0.8419\n",
      "Epoch 76/100\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0343 - accuracy: 0.9936 - val_loss: 0.8296 - val_accuracy: 0.8309\n",
      "Epoch 77/100\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0288 - accuracy: 0.9954 - val_loss: 0.7992 - val_accuracy: 0.8382\n",
      "Epoch 78/100\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0241 - accuracy: 0.9963 - val_loss: 0.8214 - val_accuracy: 0.8272\n",
      "Epoch 79/100\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0271 - accuracy: 0.9963 - val_loss: 0.8243 - val_accuracy: 0.8529\n",
      "Epoch 80/100\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0299 - accuracy: 0.9926 - val_loss: 0.8132 - val_accuracy: 0.8382\n",
      "Epoch 81/100\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0294 - accuracy: 0.9954 - val_loss: 0.8433 - val_accuracy: 0.8529\n",
      "Epoch 82/100\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0595 - accuracy: 0.9972 - val_loss: 0.8575 - val_accuracy: 0.8382\n",
      "Epoch 83/100\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0302 - accuracy: 0.9963 - val_loss: 0.8456 - val_accuracy: 0.8346\n",
      "Epoch 84/100\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0342 - accuracy: 0.9954 - val_loss: 0.8468 - val_accuracy: 0.8309\n",
      "Epoch 85/100\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0386 - accuracy: 0.9954 - val_loss: 0.8440 - val_accuracy: 0.8493\n",
      "Epoch 86/100\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0458 - accuracy: 0.9945 - val_loss: 0.8424 - val_accuracy: 0.8456\n",
      "Epoch 87/100\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0175 - accuracy: 0.9982 - val_loss: 0.8885 - val_accuracy: 0.8346\n",
      "Epoch 88/100\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0222 - accuracy: 0.9972 - val_loss: 0.8135 - val_accuracy: 0.8529\n",
      "Epoch 89/100\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0181 - accuracy: 0.9982 - val_loss: 0.8543 - val_accuracy: 0.8419\n",
      "Epoch 90/100\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0207 - accuracy: 0.9982 - val_loss: 0.9629 - val_accuracy: 0.8419\n",
      "Epoch 91/100\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0188 - accuracy: 0.9982 - val_loss: 0.8458 - val_accuracy: 0.8493\n",
      "Epoch 92/100\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0234 - accuracy: 0.9963 - val_loss: 0.8936 - val_accuracy: 0.8419\n",
      "Epoch 93/100\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0231 - accuracy: 0.9954 - val_loss: 0.7781 - val_accuracy: 0.8493\n",
      "Epoch 94/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.0491 - accuracy: 0.9908 - val_loss: 0.8254 - val_accuracy: 0.8529\n",
      "Epoch 95/100\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0321 - accuracy: 0.9945 - val_loss: 0.8560 - val_accuracy: 0.8603\n",
      "Epoch 96/100\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0164 - accuracy: 0.9982 - val_loss: 0.8433 - val_accuracy: 0.8493\n",
      "Epoch 97/100\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0286 - accuracy: 0.9972 - val_loss: 0.8543 - val_accuracy: 0.8419\n",
      "Epoch 98/100\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0184 - accuracy: 0.9972 - val_loss: 0.9052 - val_accuracy: 0.8493\n",
      "Epoch 99/100\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0271 - accuracy: 0.9917 - val_loss: 0.8047 - val_accuracy: 0.8493\n",
      "Epoch 100/100\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0382 - accuracy: 0.9972 - val_loss: 0.8001 - val_accuracy: 0.8382\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x222c1f34700>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training of data set\n",
    "m.fit(x_train, y_train, epochs=100, batch_size=64, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 1.8558 - accuracy: 0.8441\n",
      "Test accuracy: 0.84\n"
     ]
    }
   ],
   "source": [
    "# Model testing\n",
    "test_loss, test_acc = m.evaluate(x_test, y_test,\n",
    "    batch_size=None,\n",
    "    verbose='auto',\n",
    "    sample_weight=None,\n",
    "    steps=None,\n",
    "    callbacks=None,\n",
    "    max_queue_size=10,\n",
    "    workers=1,\n",
    "    use_multiprocessing=False,\n",
    "    return_dict=False )\n",
    "print(\"Test accuracy:\", round(test_acc,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Here we are using squential modelling architecture from keras model and dense from keras layers. Sequential provides training and inference features on this model. There are many hidden layers of 64, 32 and 16 units. The model is then complied with rmsprop optimizer and set to a loss function of sparse_categorical_crossentropy. The model is then split into 80:20 % and it is trained with 80% of the data, 100 epoch with a batch size of 64. Finally the model is tested with remaining percentage of data and the accuracy was found to be 84%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
